description: RL-Codegen

target:
  service: aml
  # name: V100
  # name: V10032G
  # name: A100EastUS
  # name: openai-A10080G
  # name: A10080G
  # name: gpu-v100-32g
  name: V10032G

#target:
#  service: amlk8s
#  name: itphyperdgxcl1
#  vc: bagaivc

environment:
  image: deepspeed/deepspeed:v0510_torch19_cuda111 # azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04 #pytorch/pytorch:1.9.1-cuda11.1-cudnn8-devel
  setup:
    - pip install nvsmi
    - pip install pyext==0.7

storage:
  output:
    storage_account_name: tsinterns
    container_name: t-qingru
    mount_dir: /mnt/t-qingru

code:
  local_dir: ../

jobs:
- name: RL-reward-training
  sku: 1xG8
  process_count_per_node: 1
  submit_args:
    container_args:
      cpus: 32
  command:
    # Finetuning
    #- python train.py --batch-size-per-replica 3 --grad-acc-steps 4 --epochs 10 --lr 2e-5 --save-freq 1000 --log-freq 10 --save_total_limit 5 --fp16 --tuning_mode none --model codet5-large --train-path /mnt/t-qingru/RLHF/APPS/train/
    #- pip install -r requirements.txt
    - pip install -e transformers/
    #- deepspeed train.py --batch-size-per-replica 4 --grad-acc-steps 2 --epochs 10 --lr 2e-5 --save-freq 1000 --log-freq 10 --save_total_limit 5 --tuning_mode critic --model codet5-base --fp16 --deepspeed configs/deepspeed_configs.json --train-path /mnt/t-qingru/RLHF/critic_data/APPS_critic_finetuned_2/train/ --save_dir /mnt/t-qingru/RLHF/outputs/critic/base_finetuned_temp0.6_seq20_2/
    - deepspeed train.py --batch-size-per-replica 4 --grad-acc-steps 2 --epochs 10 --lr 2e-5 --save-freq 2000 --log-freq 10 --save_total_limit 30 --tuning_mode reward-model --model codet5-base --fp16 --deepspeed configs/deepspeed_configs.json --train-path /mnt/t-qingru/RLHF/APPS_CRITIC/train/ --save_dir /mnt/t-qingru/RLHF/outputs_re/reward_model/base_finetuned_temp0.6_seq20_GT/