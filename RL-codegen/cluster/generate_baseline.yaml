description: RL-Codegen

target:
  service: aml
  # name: V100
  # name: V10032G
  # name: A100EastUS
  # name: openai-A10080G
  # name: A10080G
  # name: gpu-v100-32g
  name: V10032G

environment:
  image: pytorch/pytorch:1.9.1-cuda11.1-cudnn8-devel
  setup:
    - pip install numpy==1.21.6
    - pip install tensorboard
    - pip install tensorboardX

storage:
  output:
    storage_account_name: tsinterns
    container_name: t-qingru
    mount_dir: /mnt/t-qingru

code:
  local_dir: ../

jobs:
- name: RL-codegen-baseline
  sku: 1xG8
  process_count_per_node: 1
  submit_args:
    container_args:
      cpus: 32
  command:
    - pip install -r requirements.txt
    - pip install -e transformers/
    # Generation
    - CUDA_VISIBLE_DEVICES=0 python generate.py --model_path /mnt/t-qingru/RLHF/outputs_re/finetuning-lr2e-5_batch64-ntp/final_checkpoint/ --tokenizer_path /mnt/t-qingru/RLHF/models/codet5-large-ntp-py/ --test_path /mnt/t-qingru/RLHF/APPS_RE/train/ --output_path /mnt/t-qingru/RLHF/train_outputs/codet5-finetuned-greedy-baseline_re/codes_temp0.6_seq20/ -s 0 -e 5000 --num_seqs 1 --num_seqs_per_iter 1 --temperature 0.6 --baseline
